!pip install openimages
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

import numpy as np
import torchvision.models as models
import PIL

import os
from openimages.download import download_dataset

# Check if GPU is available
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# Set up dataset directory, number of samples per class, and class names
data_dir = "data"
number_for_samples = 600
classes = ["Goose", "Zebra", "Jellyfish"]
class_ids = [99, 340, 107]

# Create directory for images if it doesn't exist
if not os.path.exists(data_dir):
    os.makedirs(data_dir)

# Download images
print("Downloading is starting...")
download_dataset(data_dir, classes, limit=number_for_samples)

# Define transformations for image preprocessing
transform = transforms.Compose([
    transforms.Resize(256, interpolation=PIL.Image.BILINEAR),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create dataset
dataset = datasets.ImageFolder(root=data_dir, transform=transform)

# Create data loader
data_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)

# Define the CNN model
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(32 * 56 * 56, 256)
        self.fc2 = nn.Linear(256, len(classes))

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 32 * 56 * 56)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Instantiate the model
model = CNN().to(device)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
epochs = 5
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for images, labels in data_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    print(f"Epoch {epoch + 1}/{epochs}, Loss: {running_loss}")

    # Evaluation on training dataset
    model.eval()
    train_predictions = []
    train_targets = []
    with torch.no_grad():
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            train_predictions.extend(predicted.cpu().numpy())
            train_targets.extend(labels.cpu().numpy())
    train_accuracy = accuracy_score(train_targets, train_predictions)
    train_precision = precision_score(train_targets, train_predictions, average='macro')
    train_recall = recall_score(train_targets, train_predictions, average='macro')
    train_f1_score = f1_score(train_targets, train_predictions, average='macro')
    train_confusion_matrix = confusion_matrix(train_targets, train_predictions)

    print("Training Metrics:")
    print("Accuracy:", train_accuracy)
    print("Precision:", train_precision)
    print("Recall:", train_recall)
    print("F1 Score:", train_f1_score)
    print("Confusion Matrix:")
    print(train_confusion_matrix)

    # Evaluation on separate dataset (similar to training dataset)
    # Replace this part with your separate dataset and dataloader
    # For demonstration purposes, we'll reuse the training dataset for testing
    test_predictions = []
    test_targets = []
    with torch.no_grad():
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            test_predictions.extend(predicted.cpu().numpy())
            test_targets.extend(labels.cpu().numpy())
    test_accuracy = accuracy_score(test_targets, test_predictions)
    test_precision = precision_score(test_targets, test_predictions, average='macro')
    test_recall = recall_score(test_targets, test_predictions, average='macro')
    test_f1_score = f1_score(test_targets, test_predictions, average='macro')
    test_confusion_matrix = confusion_matrix(test_targets, test_predictions)

    print("Testing Metrics:")
    print("Accuracy:", test_accuracy)
    print("Precision:", test_precision)
    print("Recall:", test_recall)
    print("F1 Score:", test_f1_score)
    print("Confusion Matrix:")
    print(test_confusion_matrix)

# Save the trained model
torch.save(model.state_dict(), 'trained_model.pth')
