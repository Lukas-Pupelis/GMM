{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG_oMGrEf5vT"
      },
      "source": [
        "Užduotį atliko: Lukas Pupelis 2110612.\n",
        "\n",
        "Klasių rinkinys: Zebras (zebra), Medūza (jellyfish), Žąsis(goose).\n",
        "\n",
        "Nuotraukų įkėlimui naudojame OpenImages biblioteką."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF_bZnwJGji7"
      },
      "outputs": [],
      "source": [
        "!pip install openimages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FaucZXZgIsH"
      },
      "source": [
        "Importuojam bibliotekas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsguD1KlgKob"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj3kGAG4frEP"
      },
      "source": [
        "Tikrinam, ar veikia GPU, jei ne, imam CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWiXjllRfuXI",
        "outputId": "0c3b0fa6-3ed9-43f5-a07e-bfe002775e57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOXZCnoFfodv"
      },
      "source": [
        "Nustatome aplanko pavadinimą, nuotraukų kiekį klasėje ir klasių pavadinimus. Klasių ID imti iš https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baprr39JfpDf"
      },
      "outputs": [],
      "source": [
        "data_dir = \"data\"\n",
        "number_for_samples = 600\n",
        "classes = [\"Goose\", \"Zebra\", \"Jellyfish\"]\n",
        "class_ids = [99, 340, 107]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VziPXLyfguY"
      },
      "source": [
        "Sukuriamas aplankas nuotraukoms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9N3ZwblfhR5"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLQL4DEhfUDg"
      },
      "source": [
        "Jos atsisiunčiamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mgPbR5-fUoo"
      },
      "outputs": [],
      "source": [
        "print(\"Downloading is starting...\")\n",
        "download_dataset(data_dir, classes, limit=number_for_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSn83uPAfKMi"
      },
      "source": [
        "Transformacijos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26fkvzkIfMai"
      },
      "outputs": [],
      "source": [
        "# Define transformations for image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, interpolation=PIL.Image.BILINEAR),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbdnSYAre9To"
      },
      "source": [
        "Duomenų pakrovimas ir duomenų aibės skėlimas į dvi dalis(testavimo ir vertinimo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgeTe5ure9Ay"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "# Split the dataset into train and test subsets\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create data loaders for train and test subsets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvMeH_Oee3jB"
      },
      "source": [
        "Modelio apibrėžimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7YtaZJSeyIh"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 256)\n",
        "        self.fc2 = nn.Linear(256, len(classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 56 * 56)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSF5ShBOesf4"
      },
      "source": [
        "Modelio inicializavimas ir jo treniravimas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-iiJ6aZelEB"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSUnFyO4edAN"
      },
      "source": [
        "Testavimas su abiejais duomenų rinkiniais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jch6p4huW_s2"
      },
      "outputs": [],
      "source": [
        " # Evaluation on train dataset\n",
        "    model.eval()\n",
        "    train_predictions = []\n",
        "    train_targets = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_predictions.extend(predicted.cpu().numpy())\n",
        "            train_targets.extend(labels.cpu().numpy())\n",
        "    train_accuracy = accuracy_score(train_targets, train_predictions)\n",
        "    train_precision = precision_score(train_targets, train_predictions, average='macro')\n",
        "    train_recall = recall_score(train_targets, train_predictions, average='macro')\n",
        "    train_f1_score = f1_score(train_targets, train_predictions, average='macro')\n",
        "    train_confusion_matrix = confusion_matrix(train_targets, train_predictions)\n",
        "\n",
        "    print(\"Training Metrics:\")\n",
        "    print(\"Accuracy:\", train_accuracy)\n",
        "    print(\"Precision:\", train_precision)\n",
        "    print(\"Recall:\", train_recall)\n",
        "    print(\"F1 Score:\", train_f1_score)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(train_confusion_matrix)\n",
        "\n",
        "    # Evaluation on test dataset\n",
        "    test_predictions = []\n",
        "    test_targets = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_predictions.extend(predicted.cpu().numpy())\n",
        "            test_targets.extend(labels.cpu().numpy())\n",
        "    test_accuracy = accuracy_score(test_targets, test_predictions)\n",
        "    test_precision = precision_score(test_targets, test_predictions, average='macro')\n",
        "    test_recall = recall_score(test_targets, test_predictions, average='macro')\n",
        "    test_f1_score = f1_score(test_targets, test_predictions, average='macro')\n",
        "    test_confusion_matrix = confusion_matrix(test_targets, test_predictions)\n",
        "\n",
        "    print(\"Testing Metrics:\")\n",
        "    print(\"Accuracy:\", test_accuracy)\n",
        "    print(\"Precision:\", test_precision)\n",
        "    print(\"Recall:\", test_recall)\n",
        "    print(\"F1 Score:\", test_f1_score)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(test_confusion_matrix)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
